apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: json-to-parquet
spec:
  templates:
    - name: json-to-parquet
      inputs:
        parameters:
          - name: jsonPath
          - name: parquetPath
      volumes:
      - name: data-access-secrets
        secret:
          secretName: data-access
          defaultMode: 256
      nodeSelector:
        cloud.google.com/gke-nodepool: pvm-e2-medium-pool
      script:
        volumeMounts:
        - name: data-access-secrets
          mountPath: /run/data-access
        env:
        - name: GOOGLE_APPLICATION_CREDENTIALS
          value: /run/data-access/service-account.json
        - name: SPARK_EXECUTOR_IMAGE
          value: {{ index .Values.images "spark" }}
        image: {{ index .Values.images "spark" }}
        imagePullPolicy: IfNotPresent
        command: [python]
        source: |
          from pyspark.sql import SparkSession, types as T, functions as F, Row
          spark = (SparkSession.builder.master("local").getOrCreate())
          df = spark.read.format("json").load(path = "{{`{{inputs.parameters.jsonPath}}`}}")
          df = (df
            .withColumn("created_at", F.to_timestamp(df.created_at))
            .withColumn("comments.created_at", F.to_timestamp(df.created_at))
            .withColumn("date", ""))
          df.coalesce(1).write.format("parquet").mode("overwrite").save(path = "{{`{{inputs.parameters.parquetPath}}`}}")
